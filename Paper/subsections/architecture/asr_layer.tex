\subsection{Layer 1: Caribbean-Tuned ASR}

The ASR layer employs OpenAI's Whisper Medium fine-tuned with Low-Rank Adaptation (LoRA) on Caribbean broadcast speech. We selected Whisper Medium over Large based on Madden et al.'s \cite{madden2025} scaling law, which demonstrates that domain-specific data yields greater gains than model size for Caribbean varieties. Whisper Medium is also more efficient for Raspberry Pi 5 edge deployment.

\textbf{Fine-tuning Configuration:}
\begin{itemize}
    \item Base model: openai/whisper-medium
    \item Adaptation: LoRA (rank=16, alpha=32)
    \item Training data: BBC Caribbean broadcast corpus ($\sim$28,000 clips)
    \item Trainable parameters: $\sim$0.5\% of total model
\end{itemize}

\textbf{Confidence Scoring:} The system computes utterance-level confidence as the mean log-probability across all decoded tokens, normalized to 0-1:

\begin{equation}
\text{confidence} = \exp\left(\frac{1}{N}\sum_{i=1}^{N} \log P(t_i | t_1 \ldots t_{i-1}, \text{audio})\right)
\end{equation}

We use utterance-level rather than token-level confidence because emergency triage requires holistic assessment of transcription reliability. The low confidence threshold is set at 0.7 based on initial calibration.
