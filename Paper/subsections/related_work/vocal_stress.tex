\subsection{Vocal Stress Detection}

The bio-acoustic analysis layer of our system builds on extensive research establishing acoustic correlates of psychological stress. A systematic review analyzing 38 peer-reviewed studies found that fundamental frequency (F0) is the most consistent stress marker, with 15 of 19 studies reporting significant mean F0 increases under stress conditions \cite{schmalz2025}. Intensity and amplitude increases showed similarly consistent patterns, while speech rate, jitter, and shimmer produced heterogeneous results across studies.

\textbf{It is important to note methodological heterogeneity in this literature.} While F0 elevation is the most replicated finding, some studies report null or contradictory results depending on stress type (acute vs. chronic), measurement methodology, and population characteristics. Hansen and Patil \cite{hansen2007} found that certain stress conditions produce F0 \emph{decreases} in some speakers, particularly under conditions of extreme fatigue or hopelessness. Our system design accounts for this by using F0 as one component of a multi-feature distress score rather than a sole indicator.

Research specifically examining emergency communications provides direct validation for our approach. Van Puyvelde et al. \cite{vanpuyvelde2018} analyzed real-life emergency recordings including cockpit voice recorders and 911 calls, documenting F0 increases from 123.9 Hz to 200.1 Hz during life-threatening emergencies---a 62\% increase. F0 range expanded dramatically from 124.2 Hz to 297.3 Hz. Interestingly, jitter \emph{decreased} during emergency stress, contrary to intuition, providing an additional discriminative feature. These findings directly inform our distress detection thresholds.

Studies of actual emergency call centers demonstrate both the promise and limitations of acoustic stress detection. Lefter et al. \cite{lefter2011} achieved 4.2\% Equal Error Rate for automatic stress detection in emergency telephone calls by fusing prosodic and spectral detectors---compared to 19\% EER for individual detectors, highlighting the importance of multi-feature approaches. Demenko and JastrzÄ™bska \cite{demenko2012} found over-one-octave pitch shifts in highly stressful Polish police emergency calls, achieving 80-84\% classification accuracy.

However, a critical reality check comes from Deschamps-Berger et al. \cite{deschampsberger2021}, who found that while benchmark IEMOCAP data yielded 63\% Unweighted Accuracy for emotion recognition, real emergency calls achieved only 45.6\%---a substantial domain shift that deployment systems must account for. This finding reinforces our design decision to use bio-acoustic analysis as a triage signal rather than a sole decision-maker, routing high-distress calls to human dispatchers rather than attempting fully automated classification.

Recent work on multimodal fusion in emergency contexts supports our architecture. Feng and Devillers \cite{feng2023}, analyzing the French CEMO emergency call center corpus, found that audio components often encode more emotive information than text in crisis contexts, with multimodal fusion yielding 4-9\% absolute accuracy gains over unimodal models. This validates our approach of maintaining parallel ASR and bio-acoustic pathways that can compensate for each other's failures.
